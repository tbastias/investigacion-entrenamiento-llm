# ğŸ§± Capas del entrenamiento de un modelo

Entrenar un modelo suele involucrar varias capas:
- CÃ¡lculo numÃ©rico (tensores, operaciones)
- Uso de GPU (aceleraciÃ³n)
- Framework de deep learning
- Modelos preentrenados
- Fine-tuning optimizado

Cada librerÃ­a vive en una de esas capas.

## ğŸ”¢ NumPy

**Â¿QuÃ© es?** 
LibrerÃ­a base para cÃ¡lculo numÃ©rico en Python.

**Â¿Para quÃ© se usa?** 
- Operaciones matemÃ¡ticas.
- Arreglos y matrices.

**Importante saber:**

âŒ No se usa para entrenar modelos grandes

âœ”ï¸ Es la base conceptual de todo

## ğŸ”¥ PyTorch (torch)

**Â¿QuÃ© es?**

El framework de deep learning mÃ¡s usado hoy.

**Â¿Para quÃ© sirve?**
- Definir redes neuronales
- Entrenar modelos
- Manejar tensores
- Backpropagation automÃ¡tico

Ejemplo mental: _â€œCon PyTorch escribo el modelo y el entrenamientoâ€_

âœ”ï¸ Muy flexible

âœ”ï¸ Ideal para investigaciÃ³n y producciÃ³n

âœ”ï¸ Base de casi todo lo moderno

## ğŸš€ CUDA

**Â¿QuÃ© es?**

TecnologÃ­a de NVIDIA para usar la GPU.

**Â¿Para quÃ© sirve?**
- Acelerar cÃ¡lculos
- Entrenar modelos mucho mÃ¡s rÃ¡pido

**Importante:**

âŒ No es Python

âŒ No la usÃ¡s directamente

âœ”ï¸ PyTorch la usa por debajo

Ejemplo mental: _â€œCUDA es el motor, PyTorch es el volanteâ€_

## âš™ï¸ cuDNN

**Â¿QuÃ© es?**

LibrerÃ­a de NVIDIA optimizada para redes neuronales.

**Â¿Para quÃ© sirve?**

Operaciones rÃ¡pidas para deep learning

âœ”ï¸ Totalmente invisible para el usuario

âœ”ï¸ Se activa sola si tenÃ©s GPU compatible

## ğŸ¤— Transformers (Hugging Face)

**Â¿QuÃ© es?**

LibrerÃ­a con modelos preentrenados listos para usar.

**Â¿Para quÃ© sirve?**
- Usar LLaMA, BERT, GPT-like, etc.
- Fine-tuning
- Inferencia

Ejemplo mental: _â€œNo entreno desde cero, empiezo con un modelo ya inteligenteâ€_

âœ”ï¸ Ahorra meses de entrenamiento

âœ”ï¸ Ideal para principiantes

## ğŸ“¦ Datasets (Hugging Face)

**Â¿QuÃ© es?**

LibrerÃ­a para manejar datasets grandes.

**Â¿Para quÃ© sirve?**
- Descargar datasets
- Procesarlos
- Stream de datos

âœ”ï¸ Muy usada junto con transformers

## âš¡ Accelerate

**Â¿QuÃ© es?**

Herramienta para escalar el entrenamiento.

**Â¿Para quÃ© sirve?**
- Multi-GPU
- CPU + GPU
- ConfiguraciÃ³n simple

Ejemplo mental: _**â€œQuiero entrenar sin preocuparme por la infraestructuraâ€**_

## ğŸ§  PEFT

**Â¿QuÃ© es?**

Parameter Efficient Fine-Tuning.

**Â¿Para quÃ© sirve?**
- Fine-tuning sin entrenar todo el modelo
- TÃ©cnicas como LoRA

âœ”ï¸ Consume menos GPU

âœ”ï¸ Ideal para LLMs grandes

## ğŸ¦¥ Unsloth

**Â¿QuÃ© es?**

Framework optimizado para fine-tuning rÃ¡pido de LLMs.

**Â¿Para quÃ© sirve?**
- Fine-tuning de LLaMA, Mistral, etc.
- Mucho menos VRAM
- MÃ¡s velocidad

Ejemplo mental: _**â€œFine-tuning rÃ¡pido en una GPU chicaâ€**_

âœ”ï¸ Usa PyTorch + Transformers por debajo

âœ”ï¸ Muy popular para setups locales

## ğŸ§© BitsAndBytes

**Â¿QuÃ© es?**

LibrerÃ­a para cuantizaciÃ³n.

**Â¿Para quÃ© sirve?**
- Modelos en 4-bit / 8-bit
- Menor uso de memoria

âœ”ï¸ Clave para GPUs con poca VRAM

## ğŸ“Š Trainer (Transformers)

**Â¿QuÃ© es?**

Clase que simplifica el entrenamiento.

**Â¿Para quÃ© sirve?**
- Entrenar sin escribir mucho cÃ³digo
- Manejar epochs, logs, evaluaciÃ³n

âœ”ï¸ Ideal para empezar

âŒ Menos control fino

---

# ğŸ§  Conceptos base del entrenamiento

## Dataset

Conjunto de datos usados para entrenar el modelo.

En LLMs suele ser texto (contenido en archivos .json o .csv), que luego se transforma en tokens.

## Token

Unidad mÃ­nima de texto que entiende el modelo.

No son palabras exactas: pueden ser partes de palabras, sÃ­mbolos o signos.

## Tokenizer

Herramienta que convierte texto â†’ tokens (y viceversa).

_Ejemplo: SentencePiece, BPE, LLaMA tokenizer._

## Embedding

RepresentaciÃ³n numÃ©rica (vector) de cada token.

Permite que el modelo â€œentiendaâ€ relaciones semÃ¡nticas.

_Ejemplo: Word2Vec, LLaMA / Transformer embeddings._

---

# ğŸ“‰ Durante el entrenamiento

## Loss

FunciÃ³n que mide quÃ© tan mal estÃ¡ prediciendo el modelo.

Cuanto mÃ¡s baja la loss â†’ mejor aprende.

_Ejemplo simple: â€œÂ¿QuÃ© tan lejos estÃ¡ la respuesta del modelo de la respuesta correcta?â€_

**Herramientas:** `torch.nn.CrossEntropyLoss`, `transformers.Trainer` (la maneja internamente)

## Loss Function

FÃ³rmula matemÃ¡tica que calcula la loss.

En LLMs normalmente es Cross-Entropy Loss.

## Backward Pass (Backpropagation)

Proceso donde el modelo:
- Calcula el error (loss)
- Propaga ese error hacia atrÃ¡s
- Ajusta los pesos

**Ejemplos en uso:**
- `loss.backward()`
- `optimizer.step()`
- `optimizer.zero_grad()`

Todo esto lo maneja **PyTorch** (autograd).

## Gradient

Indica en quÃ© direcciÃ³n y cuÃ¡nto ajustar los pesos para reducir la loss.

## Optimizer

Algoritmo que usa los gradientes para actualizar los pesos.
_Ejemplos:_
- _Adam_
- _AdamW_
- _SGD_

## Learning Rate

QuÃ© tan grandes son los pasos al ajustar los pesos.

- Muy alto â†’ el modelo no converge
- Muy bajo â†’ entrena lento

## Epoch

Una pasada completa del modelo sobre todo el dataset.

## Batch

Subconjunto del dataset usado en cada paso de entrenamiento.

## Step / Iteration

Una actualizaciÃ³n del modelo usando un batch.

---

# LoRA (Low-Rank Adaptation)

## Â¿QuÃ© es? 

Un mÃ©todo para adaptar modelos grandes de IA (como LLMs o modelos de generaciÃ³n de imÃ¡genes) a tareas especÃ­ficas de forma eficiente.
    
**Â¿CÃ³mo funciona?** 

Congela los pesos originales del modelo y aÃ±ade matrices pequeÃ±as de bajo rango que se entrenan para la nueva tarea, reduciendo drÃ¡sticamente los recursos (memoria, tiempo).
- **Aplicaciones:** Personalizar chatbots para dominios especÃ­ficos, crear estilos artÃ­sticos Ãºnicos en IA generativa, o mejorar la detecciÃ³n de objetos en visiÃ³n por computadora.
- **Beneficios:** Mantiene el rendimiento del modelo completo pero con una fracciÃ³n del entrenamiento y almacenamiento. 
