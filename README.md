# ğŸ§± Capas del entrenamiento de un modelo (idea clave)

Entrenar un modelo suele involucrar varias capas:
- CÃ¡lculo numÃ©rico (tensores, operaciones)
- Uso de GPU (aceleraciÃ³n)
- Framework de deep learning
- Modelos preentrenados
- Fine-tuning optimizado

Cada librerÃ­a vive en una de esas capas.

## ğŸ”¢ NumPy

**Â¿QuÃ© es?** 
LibrerÃ­a base para cÃ¡lculo numÃ©rico en Python.

**Â¿Para quÃ© se usa?** 
- Operaciones matemÃ¡ticas.
- Arreglos y matrices.

**Importante saber:**

âŒ No se usa para entrenar modelos grandes

âœ”ï¸ Es la base conceptual de todo

## ğŸ”¥ PyTorch (torch)

**Â¿QuÃ© es?**

El framework de deep learning mÃ¡s usado hoy.

**Â¿Para quÃ© sirve?**
- Definir redes neuronales
- Entrenar modelos
- Manejar tensores
- Backpropagation automÃ¡tico

Ejemplo mental: _â€œCon PyTorch escribo el modelo y el entrenamientoâ€_

âœ”ï¸ Muy flexible

âœ”ï¸ Ideal para investigaciÃ³n y producciÃ³n

âœ”ï¸ Base de casi todo lo moderno

## ğŸš€ CUDA

**Â¿QuÃ© es?**

TecnologÃ­a de NVIDIA para usar la GPU.

**Â¿Para quÃ© sirve?**
- Acelerar cÃ¡lculos
- Entrenar modelos mucho mÃ¡s rÃ¡pido

**Importante:**

âŒ No es Python

âŒ No la usÃ¡s directamente

âœ”ï¸ PyTorch la usa por debajo

Ejemplo mental: _â€œCUDA es el motor, PyTorch es el volanteâ€_

## âš™ï¸ cuDNN

**Â¿QuÃ© es?**

LibrerÃ­a de NVIDIA optimizada para redes neuronales.

**Â¿Para quÃ© sirve?**

Operaciones rÃ¡pidas para deep learning

âœ”ï¸ Totalmente invisible para el usuario

âœ”ï¸ Se activa sola si tenÃ©s GPU compatible

## ğŸ¤— Transformers (Hugging Face)

**Â¿QuÃ© es?**

LibrerÃ­a con modelos preentrenados listos para usar.

**Â¿Para quÃ© sirve?**
- Usar LLaMA, BERT, GPT-like, etc.
- Fine-tuning
- Inferencia

Ejemplo mental: _â€œNo entreno desde cero, empiezo con un modelo ya inteligenteâ€_

âœ”ï¸ Ahorra meses de entrenamiento

âœ”ï¸ Ideal para principiantes

## ğŸ“¦ Datasets (Hugging Face)

**Â¿QuÃ© es?**

LibrerÃ­a para manejar datasets grandes.

**Â¿Para quÃ© sirve?**
- Descargar datasets
- Procesarlos
- Stream de datos

âœ”ï¸ Muy usada junto con transformers

## âš¡ Accelerate

**Â¿QuÃ© es?**

Herramienta para escalar el entrenamiento.

**Â¿Para quÃ© sirve?**
- Multi-GPU
- CPU + GPU
- ConfiguraciÃ³n simple

Ejemplo mental: _**â€œQuiero entrenar sin preocuparme por la infraestructuraâ€**_

## ğŸ§  PEFT

**Â¿QuÃ© es?**

Parameter Efficient Fine-Tuning.

**Â¿Para quÃ© sirve?**
- Fine-tuning sin entrenar todo el modelo
- TÃ©cnicas como LoRA

âœ”ï¸ Consume menos GPU

âœ”ï¸ Ideal para LLMs grandes

## ğŸ¦¥ Unsloth

**Â¿QuÃ© es?**

Framework optimizado para fine-tuning rÃ¡pido de LLMs.

**Â¿Para quÃ© sirve?**
- Fine-tuning de LLaMA, Mistral, etc.
- Mucho menos VRAM
- MÃ¡s velocidad

Ejemplo mental: _**â€œFine-tuning rÃ¡pido en una GPU chicaâ€**_

âœ”ï¸ Usa PyTorch + Transformers por debajo

âœ”ï¸ Muy popular para setups locales

## ğŸ§© BitsAndBytes

**Â¿QuÃ© es?**

LibrerÃ­a para cuantizaciÃ³n.

**Â¿Para quÃ© sirve?**
- Modelos en 4-bit / 8-bit
- Menor uso de memoria

âœ”ï¸ Clave para GPUs con poca VRAM

## ğŸ“Š Trainer (Transformers)

**Â¿QuÃ© es?**

Clase que simplifica el entrenamiento.

**Â¿Para quÃ© sirve?**
- Entrenar sin escribir mucho cÃ³digo
- Manejar epochs, logs, evaluaciÃ³n

âœ”ï¸ Ideal para empezar

âŒ Menos control fino
